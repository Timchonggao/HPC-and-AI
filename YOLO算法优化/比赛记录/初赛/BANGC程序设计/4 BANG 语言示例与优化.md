## BANG 语言示例与优化



### 以矩阵乘为例的BANG C编程实验



### 前言

整篇文章首先介绍BANG C开发的整个流程，以具体例子（矩阵乘）来详细介绍BANG C的开发和优化，最后展示每一步优化的性能情况。



### 一、概述

BANG C是寒武纪针对MLU硬件提出的专用编程语言，它由C语言扩展而来。BANG C采用异构编程，一个完整的BANG C程序在HOST端和MLU端分别进行编程、编译，最后链接成一个可执行程序。

HOST端使用C/C++语言进行编写，调用寒武纪的CNRT接口执行控制部分和串行任务；MLU端使用BANG C编写，执行计算部分和并行任务。

用户在HOST端输入数据，做一定的处理后，通过Kernel启动函数将相应输入数据传给MLU端，MLU端进行计算，再将计算结果拷回HOST端。

接下来就以矩阵乘的程序示例详细介绍BANG C的编程过程，以及如何利用MLU硬件架构优势去优化。编程技巧和优化的部分涵盖了片上数据调度，计算向量化操作及相应的数据对齐操作，任务多核拆分，流水线的优化技巧等。



### 二、HOST端实现









实现神经网络算法到mlu平台的移植，使用pytorch用户手册，基于硬件架构实现优化

神经网络算法移植的整个过程，运行CPU模式





如何使用平台进行算子设计，算子设计基于硬件架构



神经网络移植之后，性能分析，使用官方的算子或者自己设计的算子



