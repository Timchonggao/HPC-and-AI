

### 提升train的速度,相对提升量

1. 训练流程，分析性能瓶颈（做一个图，横坐标为训练流程，纵坐标为利用率），分析工作流，标记时间戳分析性能瓶颈。
2. 单个GPU和多个GPU模式
3. 调参脚本，写一个脚本，重定向生成log文件
4. cpu并行模式
5. 运行C++版本
6. 尝试76结点机器跑一下，不同操作系统的结果可能有不同的结果



某一天，都看不同部分源码，然后进行交流，清楚流程







make improvements and analysis on the **training procedure.**   

**speed up the training procedure** or **reduce the computational needs** for this task.  









关于 ASC 培训的回放，里面是有一些提示的，我觉得咱们要做的事主要如下：  

1. 调三个参数组合”model/descriptor/precision”,“model/ftting net/precision” ,”model/descriptor/type one side” 训练一个 baseline模型，该模型需要满足精度要求，在此基准模型上优化训练过程，最终主要评判标准为优化后的训练速度和所选的基准模型的训练速度比较的相对提升量。同时选定的基准模型应该满足精度要求，且优化后只允许改变训练速度，精度只能在一定范围内波动。  
2. 单 GPU 训练优化：分析程序性能瓶颈，寻找优化策略，可以参考 fgure1，视频里的提示有（可能不止这些）：
   - 两次反向求导的计算量很大，占用时间比较大，可以考虑优化这部分。  
   - 自定义的算子可以考虑用 kernel fussion 策略优化。  
3. 多 GPU 训练优化：分析出源码中 GPU 并行训练的具体实现，寻找更好的 GPU优化策略，可以参考 fgure1，视频里的提示有：  
   - 第一步坐标转化为相对坐标, 需要对周围原子相对位置进行计算, 最好对空间进行分块, 然后用多 GPU 处理  
4. 测试 C++ 版本并进行优化。  
5. 测试 CPU 并行模式。  
6. 在不同的机器上测试。  
7. 做文献综述和总结测试过程。  

![image-20220202013546048](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220202013546048.png)





使用py-spy工具分析python代码的执行流程,分析出热点函数和算子,下一步是如何优化



看常见的优化方式,理解程序的执行流程细节和具体部分



分析profile的结果，深入源码，理解TensorFlow的流程，TensorFlow的分析工具，TensorFlow的优化方法



**单GPU训练**

分析profile的结果：py-spy结果分析；nvprof分析；self-profile结果分析；TensorBoard分析

深入源码，理解TensorFlow的流程和优化方法

阅读文献，开始着手写作

**多GPU训练**

分析profile的结果：py-spy结果分析；nvprof分析；self-profile结果分析；TensorBoard分析

理解并行方法







make improvements and analysis on the training procedure

分析代码结构和流程，提升训练速度

make improvement to speed up the training procedure on GPUs.

加速多GPU的训练速度

analysis on the improvement and submit the modified code with a detailed report,  containing the understanding of DeePMD-kit, the specific optimization method and improvement.

分析加速方法，提交修改后的代码，自己对DeepMD-kit的理解，具体的优化方法















