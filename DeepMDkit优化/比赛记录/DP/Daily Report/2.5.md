

**高冲:**

**dp train的探索**

使用python画图工具pyplot分析lcurve.out文件,由于linux服务器没有GUI界面,可以先将图片保存为png文件,然后通过xshell使用sz命令发送至本机电脑

![figure](C:\Users\86183\Desktop\figure.png)

使用dp train之前可以先配置三个环境变量

```
export OMP_NUM_THREADS=1 //一般修改这个参数
export TF_INTRA_OP_PARALLELISM_THREADS=0
export TF_INTER_OP_PARALLELISM_THREADS=0	
```

OMP_NUM_THREADS  - 指定要使用的线程数。

intra_op_parallelism_threads 控制运算符op内部的并行:当运算符op为单一运算符,并且内部可以实现并行时，如矩阵乘法,reduce_sum之类的操作，可以设置intra_op_parallelism_threads参数来并行, intra代表内部.
inter_op_parallelism_threads 控制多个运算符op之间的并行计算:当有多个运算符op，并且他们之间比较独立，运算符和运算符之间没有直接的路径Path相连.Tensorflow会尝试并行地计算他们,使用由inter_op_parallelism_threads参数来控制数量的一个线程池.

单GPU时,提高指定线程数可以稍微提高GPU的利用率,大概由48%提高至55%,多GPU并行时,出现GPU的利用率下降的现象(4个GPU并行只有25%的利用率),随着并行GPU的数量越多,GPU利用率下降越大(这里可能可以写一个脚本得到最优的线程数和并行GPU的数目)



分析dp train的细节:

对与在运行dp的时候,开始不理解是cpu还是gpu这一问题,通过GPU性能分析watch -n 1 nvidia smi可以看到GPU确实在使用,调整OMP_NUM_THREADS TF_INTRA_OP_PARALLELISM_THREADS TF_INTER_OP_PARALLELISM_THREADS这三个参数之后仍然是一个GPU,GPU利用率提高一些,为55%左右默认情况为48%左右,可以分析到这里提高线程数,可以稍微提高GPU利用率

![image-20220205232418289](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205232418289.png)

![image-20220205232454708](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205232454708.png)



默认的配置应该是

```
export OMP_NUM_THREADS=1  
export TF_INTRA_OP_PARALLELISM_THREADS=0
export TF_INTER_OP_PARALLELISM_THREADS=0	
dp train input.json
```



使用horovodrun -np 4 dp train input.json命令,需要修改之前参数为默认为1 0 0,然后执行以下命令:

```
CUDA_VISIBLE_DEVICES=0,1,2,3 mpirun -np 2 dp train input.json -l train.log
```

可以看到CPU进程数为4,GPU使用数目为4,但是GPU利用率不高,只有25%左右,这里调指定线程数不能提高GPU利用率,这里是直接调节每个GPU的线程数目

调节使用的GPU个数看是否能够提高GPU的利用率



CPU进程应该只与GPU使用数目相同,一个CPU进程需要管理一个GPU的资源调度







