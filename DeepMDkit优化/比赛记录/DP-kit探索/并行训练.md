

多 GPU 训练优化：分析出源码中 GPU 并行训练的具体实现，寻找更好的 GPU优化策略，可以参考 fgure1，视频里的提示有：  

- 第一步坐标转化为相对坐标, 需要对周围原子相对位置进行计算, 最好对空间进行分块, 然后用多 GPU 处理  



## 并行训练

Currently, parallel training is enabled in a sychoronized way with help of [Horovod](https://github.com/horovod/horovod).Depend on the number of training processes (according to MPI context) and number of GPU cards avaliable, DeePMD-kit will decide whether to launch the training in parallel (distributed) mode or in serial mode. Therefore, no additional options is specified in your JSON/YAML input file.

Horovod works in the data-parallel mode, resulting in a larger global batch size.

### 理解ho和MPI



### Tuning learning rate

Horovod works in the data-parallel mode, resulting in a larger global batch size. For example, the real batch size is 8 when `batch_size` is set to 2 in the input file and you launch 4 workers. Thus, `learning_rate` is automatically scaled by the number of workers for better convergence. Technical details of such heuristic rule are discussed at [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677).

The number of decay steps required to achieve same accuracy can decrease by the number of cards (e.g., 1/2 of steps in the above case), but needs to be scaled manually in the input file.

In some cases, it won’t work well when scale learning rate by worker count in a `linear` way. Then you can try `sqrt` or `none` by setting argument `scale_by_worker` like below.

```shell
    "learning_rate" :{
        "scale_by_worker": "none",
        "type": "exp"
    }
```

有时候为了更好的收敛效果,需要调整learning_rate的参数



The following command launches 4 processes on the same host:

```
CUDA_VISIBLE_DEVICES=0,
horovodrun -np 4 dp train --mpi-log=workers input.json
```



DEEPMD INFO    wall time: 395.781 s





输出文件lcurveout

```
#  step      rmse_trn    rmse_e_trn    rmse_f_trn         lr
      0      2.53e+01      5.80e-01      7.99e-01    5.0e-04
    100      9.97e+00      3.36e-02      3.15e-01    5.0e-04
    200      7.61e+00      2.41e-02      2.41e-01    5.0e-04
    300      7.22e+00      1.12e-01      2.28e-01    5.0e-04
    400      6.72e+00      5.31e-02      2.13e-01    5.0e-04
    500      7.22e+00      6.63e-02      2.28e-01    5.0e-04
    600      6.71e+00      1.04e-01      2.12e-01    5.0e-04
    700      5.90e+00      2.16e-02      1.86e-01    5.0e-04
    800      5.21e+00      4.73e-02      1.65e-01    5.0e-04
    900      7.26e+00      2.30e-02      2.29e-01    5.0e-04
   1000      6.45e+00      5.11e-02      2.04e-01    5.0e-04
   1100      5.77e+00      1.74e-01      1.82e-01    5.0e-04
   1200      5.83e+00      3.25e-02      1.84e-01    5.0e-04
   1300      5.43e+00      1.41e-01      1.72e-01    5.0e-04
   1400      5.32e+00      9.07e-02      1.68e-01    5.0e-04
   1500      4.79e+00      1.53e-01      1.51e-01    5.0e-04
   1600      4.51e+00      6.89e-03      1.43e-01    5.0e-04
   1700      4.56e+00      1.79e-01      1.44e-01    5.0e-04
   1800      5.06e+00      9.29e-02      1.60e-01    5.0e-04
   1900      4.43e+00      2.23e-02      1.40e-01    5.0e-04
   2000      4.70e+00      5.04e-02      1.48e-01    5.0e-04
   2100      4.68e+00      1.58e-01      1.48e-01    5.0e-04
   2200      4.40e+00      1.73e-01      1.39e-01    5.0e-04
   2300      4.61e+00      1.05e-01      1.46e-01    5.0e-04
   2400      4.41e+00      6.94e-03      1.39e-01    5.0e-04
   2500      4.92e+00      1.60e-01      1.55e-01    5.0e-04
   2600      5.24e+00      1.60e-02      1.66e-01    5.0e-04
   2700      5.13e+00      1.85e-01      1.62e-01    5.0e-04
   2800      4.33e+00      2.50e-01      1.36e-01    5.0e-04
   2900      4.82e+00      4.47e-02      1.52e-01    5.0e-04
   3000      4.17e+00      1.71e-02      1.32e-01    5.0e-04
   3100      3.79e+00      1.15e-01      1.20e-01    5.0e-04
   3200      4.12e+00      9.02e-02      1.30e-01    5.0e-04
   3300      3.97e+00      2.40e-02      1.26e-01    5.0e-04
   3400      4.51e+00      9.57e-02      1.42e-01    5.0e-04
   3500      4.25e+00      7.82e-02      1.34e-01    5.0e-04
   3600      4.06e+00      2.44e-01      1.27e-01    5.0e-04
   3700      4.00e+00      2.48e-01      1.26e-01    5.0e-04
   3800      4.09e+00      1.39e-01      1.29e-01    5.0e-04
   3900      4.27e+00      8.00e-02      1.35e-01    5.0e-04
   4000      3.59e+00      2.02e-01      1.13e-01    5.0e-04
   4100      4.72e+00      3.59e-02      1.49e-01    5.0e-04
   4200      3.90e+00      9.64e-02      1.23e-01    5.0e-04
   4300      3.93e+00      7.40e-02      1.24e-01    5.0e-04
   4400      3.63e+00      2.00e-01      1.14e-01    5.0e-04
   4500      3.85e+00      1.80e-01      1.21e-01    5.0e-04

```



```shell
dp train input.json -l train.log
```

可以输出log文件



##### GPU利用率

watch -n 1 nvidia-smi



并行训练

```
export OMP_NUM_THREADS=1
export TF_INTRA_OP_PARALLELISM_THREADS=0
export TF_INTER_OP_PARALLELISM_THREADS=0
```



```
export CUDA_VISIBLE_DEVICES=0,1,2,3 
mpirun -np 4 dp train input.json -l train.log
smpirun -np 4 dp train input.json -l train.log
# mpirun -np 4 dp train -l mpi.log -m workers input.json
# mpirun -l -launcher=fork -hosts=localhost -np 4 dp train --mpi-log=workers input.json //此命令会对每个GPU生成一个log文件
# horovodrun -np 4 dp train input.json -l train_hov.log
```

![image-20220210161310998](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220210161310998.png)

默认配置并行训练大约28%的利用率



##### logging设置

What’s more, 2 command-line arguments are defined to control the logging behvaior when performing parallel training with MPI.

```shell
optional arguments:
  -l LOG_PATH, --log-path LOG_PATH
                        set log file to log messages to disk, if not
                        specified, the logs will only be output to console
                        (default: None)
  -m {master,collect,workers}, --mpi-log {master,collect,workers}
                        Set the manner of logging when running with MPI.
                        'master' logs only on main process, 'collect'
                        broadcasts logs from workers to master and 'workers'
                        means each process will output its own log (default:
                        master)
```

```
[3] DEEPMD rank:3  INFO    batch     200 training time 4.37 s, testing time 0.00 s
[2] DEEPMD rank:2  INFO    batch     200 training time 4.38 s, testing time 0.00 s
[1] DEEPMD rank:1  INFO    batch     200 training time 4.37 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     200 training time 4.21 s, testing time 0.04 s
[2] DEEPMD rank:2  INFO    batch     300 training time 4.35 s, testing time 0.00 s
[3] DEEPMD rank:3  INFO    batch     300 training time 4.31 s, testing time 0.00 s
[1] DEEPMD rank:1  INFO    batch     300 training time 4.32 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     300 training time 4.23 s, testing time 0.05 s
[1] DEEPMD rank:1  INFO    batch     400 training time 4.32 s, testing time 0.00 s
[2] DEEPMD rank:2  INFO    batch     400 training time 4.29 s, testing time 0.00 s
[3] DEEPMD rank:3  INFO    batch     400 training time 4.36 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     400 training time 4.29 s, testing time 0.05 s
[2] DEEPMD rank:2  INFO    batch     500 training time 4.35 s, testing time 0.00 s
[1] DEEPMD rank:1  INFO    batch     500 training time 4.37 s, testing time 0.00 s
[3] DEEPMD rank:3  INFO    batch     500 training time 4.31 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     500 training time 4.25 s, testing time 0.05 s
[1] DEEPMD rank:1  INFO    batch     600 training time 4.31 s, testing time 0.00 s
[2] DEEPMD rank:2  INFO    batch     600 training time 4.28 s, testing time 0.00 s
[3] DEEPMD rank:3  INFO    batch     600 training time 4.27 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     600 training time 4.21 s, testing time 0.04 s
[1] DEEPMD rank:1  INFO    batch     700 training time 4.35 s, testing time 0.00 s
[3] DEEPMD rank:3  INFO    batch     700 training time 4.36 s, testing time 0.00 s
[2] DEEPMD rank:2  INFO    batch     700 training time 4.31 s, testing time 0.00 s
[0] DEEPMD rank:0  INFO    batch     700 training time 4.23 s, testing time 0.05 s
```

#### 主进程的训练速度总比从进程的快一些



#### data下的数训练需要等待的时间比example下的数据久一点



使用tensorboard后GPU利用率下降

![image-20220210164839681](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220210164839681.png)

使用tensorboard之前的利用率

![image-20220210172155574](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220210172155574.png)

**Allowing the tensorboard analysis will takes extra execution time.**(eg, 15% increasing @Nvidia GTX 1080Ti double precision with default water sample)







什么是并行:

任务并行吗,将10000个batch分配成4个2500batch,最后整合在一起

GPU怎么访问CPU的,是CPU将一份相同的数据拿出同时给4个GPU读取,还是CPU将数据分成4块,每块GPU读不同的数据?

内部操作是否可以并行呢,比如将数据分块并行



![image-20220212225842118](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220212225842118.png)



![image-20220212225829119](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220212225829119.png)

**训练时间段,GPU利用率反而低**







### 分析并行的细节

**修改input.json中timeline和TensorBoard，将setup.py中cpu改为CUDA，将gcc版本改为1.1.0**
