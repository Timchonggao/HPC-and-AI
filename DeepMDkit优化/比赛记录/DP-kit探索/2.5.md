优化DP train,首先先理解train的过程,方法和分析方法

1. **tensorboard分析工具使用,Tensorboard can be used to visualize training procedure**
2. **implements MPI and GPU supports, makes it highly efficient for high performance parallel and distributed computing.**



基本dp train,修改input.json文件,使用并行训练的方式,并使用分析工具

```shell
dp train input.json
```

输出信息如下:

```
DEEPMD INFO    ---Summary of DataSystem: training     -----------------------------------------------
DEEPMD INFO    found 3 system(s):
DEEPMD INFO                                        system  natoms  bch_sz   n_bch   prob  pbc
DEEPMD INFO                         ../data_water/data_0/     192       1      80  0.250    T
DEEPMD INFO                         ../data_water/data_1/     192       1     160  0.500    T
DEEPMD INFO                         ../data_water/data_2/     192       1      80  0.250    T
DEEPMD INFO    --------------------------------------------------------------------------------------
DEEPMD INFO    ---Summary of DataSystem: validation   -----------------------------------------------
DEEPMD INFO    found 1 system(s):
DEEPMD INFO                                        system  natoms  bch_sz   n_bch   prob  pbc
DEEPMD INFO                          ../data_water/data_3     192       1      80  1.000    T
DEEPMD INFO    --------------------------------------------------------------------------------------
```

输出文件lecurve.out文件如下:

```
#  step      rmse_val    rmse_trn    rmse_e_val  rmse_e_trn    rmse_f_val  rmse_f_trn         lr
      0      3.33e+01    3.41e+01      1.03e+01    1.03e+01      8.39e-01    8.72e-01    1.0e-03
    100      2.57e+01    2.56e+01      1.87e+00    1.88e+00      8.03e-01    8.02e-01    1.0e-03
    200      2.45e+01    2.56e+01      2.26e-01    2.21e-01      7.73e-01    8.10e-01    1.0e-03
    300      1.62e+01    1.66e+01      5.01e-02    4.46e-02      5.11e-01    5.26e-01    1.0e-03
    400      1.36e+01    1.32e+01      1.07e-02    2.07e-03      4.29e-01    4.19e-01    1.0e-03
    500      1.07e+01    1.05e+01      2.45e-03    4.11e-03      3.38e-01    3.31e-01    1.0e-03
```

文件分析如下: **xshell如法显示plt的图片,可以将生成的图片保存然后使用sz命令发送至电脑**

```python
import numpy as np
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt

data = np.genfromtxt("lcurve.out", names=True)
for name in data.dtype.names[1:-1]:
    plt.plot(data['step'], data[name], label=name)
plt.legend()
plt.xlabel('Step')
plt.ylabel('Loss')
plt.xscale('symlog')
plt.yscale('symlog')
plt.grid()
plt.show()
plt.savefig('lcurve.png')
```



```
$ dp train --help

An explanation will be provided


positional arguments:
  INPUT                 the input json database

optional arguments:
  -h, --help            show this help message and exit
 
  --init-model INIT_MODEL
                        Initialize a model by the provided checkpoint

  --restart RESTART     Restart the training from the provided checkpoint
 
  --init-frz-model INIT_FRZ_MODEL
                        Initialize the training from the frozen model.
```





**在运行dp的时候,是cpu还是gpu**

在一些资源有限的机器上，可能需要控制 DeePMD-kit 使用的线程数。这是通过三个环境变量实现的`OMP_NUM_THREADS`：`TF_INTRA_OP_PARALLELISM_THREADS`和`TF_INTER_OP_PARALLELISM_THREADS`。`OMP_NUM_THREADS`控制 DeePMD-kit 实现操作的多线程。`TF_INTRA_OP_PARALLELISM_THREADS`和`TF_INTER_OP_PARALLELISM_THREADS`控件`intra_op_parallelism_threads`和`inter_op_parallelism_threads`，它们是用于多线程的 Tensorflow 配置。[在这里](https://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads)可以找到解释。

例如，如果您希望在一个节点上使用 2 个 CPU 的 3 个核心，您可以设置环境变量并运行 DeePMD-kit，如下所示：

```bash
export OMP_NUM_THREADS=6
export TF_INTRA_OP_PARALLELISM_THREADS=3
export TF_INTER_OP_PARALLELISM_THREADS=2
dp train input.json
```



```bash
export OMP_NUM_THREADS=10 //线程数
export TF_INTRA_OP_PARALLELISM_THREADS=10 //核数
export TF_INTER_OP_PARALLELISM_THREADS=1 //CPU个数
dp train input.json
```

![image-20220205193909444](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205193909444.png)



全部设置为1

![image-20220205201800232](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205201800232.png)

![image-20220205201921698](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205201921698.png)

**发现没有设置GPU,这里是有使用GPU的,0表示GPU标号为0**







```bash
export OMP_NUM_THREADS=1
export TF_INTRA_OP_PARALLELISM_THREADS=0
export TF_INTER_OP_PARALLELISM_THREADS=0
dp train input.json
```

WARNING:tensorflow:From /home/asc22g0/GC/env/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:root:Environme下`nt variable KMP_BLOCKTIME is empty. Use the default value 0
WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0
/home/asc22g0/GC/env/lib/python3.7/importlib/__init__.py:169: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.
  _bootstrap._exec(spec, module)
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #211: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #209: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 20 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #213: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 

![image-20220205194516068](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205194516068.png)





## 结论

调节线程数可以稍微调高一些GPU使用率,但是线程数过高会导致下降一些但是还是稍微提高



**可以画出一条曲线分析**







**GPU利用率查看**

watch -n 1 nvidia-smi

**CPU利用率查看**





可以设置其他环境变量：

| 环境变量          | 允许值       | 默认值 | 用法                                 |
| ----------------- | ------------ | ------ | ------------------------------------ |
| DP_INTERFACE_PREC | `high`,`low` | `high` | 控制训练的高（双）或低（浮动）精度。 |



```
# 查看物理CPU个数
cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l

# 查看每个物理CPU中core的个数(即核数)
cat /proc/cpuinfo| grep "cpu cores"| uniq

# 查看逻辑CPU的个数
cat /proc/cpuinfo| grep "processor"| wc -l

(/home/asc22g0/GC/env) asc22g0@good-DGX-Station:~/GC/data/zip/water$ cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l
1
(/home/asc22g0/GC/env) asc22g0@good-DGX-Station:~/GC/data/zip/water$ cat /proc/cpuinfo| grep "cpu cores"| uniq
cpu cores       : 20
(/home/asc22g0/GC/env) asc22g0@good-DGX-Station:~/GC/data/zip/water$ cat /proc/cpuinfo| grep "processor"| wc -l
40
CPU总核数 = 物理CPU个数 * 每颗物理CPU的核数
总逻辑CPU数 = 物理CPU个数 * 每颗物理CPU的核数 * 超线程数
```







**使用horovodrun -np 4 dp train input.json语句,仍然显示没有调用GPU,后面发现是使用了GPU的**

WARNING:tensorflow:From /home/asc22g0/GC/env/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:tensorflow:From /home/asc22g0/GC/env/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:tensorflow:From /home/asc22g0/GC/env/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:tensorflow:From /home/asc22g0/GC/env/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0
WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0
WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0
WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0
WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0
WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0
WARNING:root:Environment variable KMP_BLOCKTIME is empty. Use the default value 0
WARNING:root:Environment variable KMP_AFFINITY is empty. Use the default value granularity=fine,verbose,compact,1,0



![image-20220205203247970](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205203247970.png)



![image-20220205205605318](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205205605318.png)

修改之前三个参数为1 0 0后提高性能

![image-20220205213225898](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220205213225898.png)

```
CUDA_VISIBLE_DEVICES=0,1,2,3 mpirun -np 4 dp train input.json -l train.log
```



参数为2 0 0,性能稍微提高了一些

![image-20220206002153783](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220206002153783.png)

![image-20220206003222894](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220206003222894.png)



参数为 4 0 0,这里是直接指定每个GPU的线程数目,也就是说有4*4=16个线程

![image-20220206000623457](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220206000623457.png)

性能没有提高,CPU的线程比较多,而且线程过多可能不稳定



参数为 1 0 0,使用两张GPU进行训练,利用率提高

![image-20220206003941201](C:\Users\86183\AppData\Roaming\Typora\typora-user-images\image-20220206003941201.png)







- 将CPU线程数作为参数进行调节,可以提高单GPU的利用率
- 将CPU线程数和GPU并行数作为参数进行调节,分析GPU利用率的最高点





研究脚本调参

阅读源码进一步分析GPU利用率低的原因,可以使用tensorboard分析工具和python程序性能分析工具

理解ho和MPI的区别





**可修改参数如下:**

"model/descriptor/precision”, “model/fitting_net/precision" and "model/descriptor/type_one_side"  



